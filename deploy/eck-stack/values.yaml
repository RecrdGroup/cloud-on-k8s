eck-enterprise-search:
  enabled: false

eck-agent:
  enabled: false

eck-fleet-server:
  enabled: false

eck-beats:
  enabled: false

eck-logstash:
  enabled: false

eck-apm-server:
  enabled: false

eck-elasticsearch:
  enabled: true
  # This is adjusting the full name of the elasticsearch resource so that both the eck-elasticsearch
  # and the eck-kibana chart work together by default in the eck-stack chart.
  fullnameOverride: elasticsearch

  nodeSets:
    - name: master
      count: 1
      config:
        node.roles: ["master"]
        # Comment out when setting the vm.max_map_count via initContainer, as these are mutually exclusive.
        # For production workloads, it is strongly recommended to increase the kernel setting vm.max_map_count to 262144
        # and leave node.store.allow_mmap unset.
        # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
        #
        node.store.allow_mmap: false
      podTemplate:
        spec:
          containers:
            - name: elasticsearch
              resources:
                limits:
                  memory: 2Gi
                  cpu: 1
          # Affinity/Anti-affinity settings for controlling the 'spreading' of Elasticsearch
          # pods across existing hosts.
          # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
          # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-advanced-node-scheduling.html#k8s-affinity-options
          #
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/elasticsearch
                        operator: In
                        values:
                          - "true"
          tolerations:
            - key: "beta.kubernetes.io/elasticsearch"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      # Volume Claim settings.
      # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-volume-claim-templates.html
      #
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 100Gi
            # Adjust to your storage class name
            #
            # storageClassName: local-storage
    - name: hot
      count: 1
      config:
        node.roles: ["data_hot", "data_content", "ingest"]
        # Comment out when setting the vm.max_map_count via initContainer, as these are mutually exclusive.
        # For production workloads, it is strongly recommended to increase the kernel setting vm.max_map_count to 262144
        # and leave node.store.allow_mmap unset.
        # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
        #
        node.store.allow_mmap: false
      podTemplate:
        spec:
          containers:
            - name: elasticsearch
              resources:
                limits:
                  memory: 2Gi
                  cpu: 1
          # Affinity/Anti-affinity settings for controlling the 'spreading' of Elasticsearch
          # pods across existing hosts.
          # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
          # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-advanced-node-scheduling.html#k8s-affinity-options
          #
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/elasticsearch
                        operator: In
                        # This should be adjusted to the instance type according to your setup
                        #
                        values:
                          - "true"
          tolerations:
            - key: "beta.kubernetes.io/elasticsearch"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      # Volume Claim settings.
      # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-volume-claim-templates.html
      #
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 100Gi
            # Adjust to your storage class name
            #
            # storageClassName: local-storage
    - name: warm
      count: 1
      config:
        node.roles: ["data_warm"]
        # Comment out when setting the vm.max_map_count via initContainer, as these are mutually exclusive.
        # For production workloads, it is strongly recommended to increase the kernel setting vm.max_map_count to 262144
        # and leave node.store.allow_mmap unset.
        # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
        #
        node.store.allow_mmap: false
      podTemplate:
        spec:
          containers:
            - name: elasticsearch
              resources:
                limits:
                  memory: 2Gi
                  cpu: 1
          # Affinity/Anti-affinity settings for controlling the 'spreading' of Elasticsearch
          # pods across existing hosts.
          # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
          # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-advanced-node-scheduling.html#k8s-affinity-options
          #
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: beta.kubernetes.io/elasticsearch
                        operator: In
                        # This should be adjusted to the instance type according to your setup
                        #
                        values:
                          - "true"
          tolerations:
            - key: "beta.kubernetes.io/elasticsearch"
              operator: "Equal"
              value: "true"
              effect: "NoSchedule"
      # Volume Claim settings.
      # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-volume-claim-templates.html
      #
      volumeClaimTemplates:
        - metadata:
            name: elasticsearch-data
          spec:
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 100Gi
            # Adjust to your storage class name
            #
            # storageClassName: local-storage
          #    - name: cold
          #      count: 1
          #      config:
          #        node.roles: ["data_cold"]
          # Comment out when setting the vm.max_map_count via initContainer, as these are mutually exclusive.
          # For production workloads, it is strongly recommended to increase the kernel setting vm.max_map_count to 262144
          # and leave node.store.allow_mmap unset.
          # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html
          #
          #        node.store.allow_mmap: false
          #      podTemplate:
          #        spec:
          #          containers:
          #            - name: elasticsearch
          #              resources:
          #                limits:
          #                  memory: 8Gi
          #                  cpu: 2
          # Affinity/Anti-affinity settings for controlling the 'spreading' of Elasticsearch
          # pods across existing hosts.
          # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
          # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-advanced-node-scheduling.html#k8s-affinity-options
          #
          # affinity:
          #   nodeAffinity:
          #     requiredDuringSchedulingIgnoredDuringExecution:
          #       nodeSelectorTerms:
          #       - matchExpressions:
          #         - key: beta.kubernetes.io/instance-type
          #           operator: In
          #           # This should be adjusted to the instance type according to your setup
          #           #
          #           values:
          #           - highstorage
      # Volume Claim settings.
      # ref: https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-volume-claim-templates.html
      #
#      volumeClaimTemplates:
#        - metadata:
#            name: elasticsearch-data
#          spec:
#            accessModes:
#              - ReadWriteOnce
#            resources:
#              requests:
#                storage: 20Ti
#            # Adjust to your storage class name
#            #
#            # storageClassName: local-storage


# If enabled, will use the eck-kibana chart and deploy a Kibana resource.
#
eck-kibana:
  enabled: true
  spec:
    # This is also adjusting the kibana reference to the elasticsearch resource named previously so that
    # both the eck-elasticsearch and the eck-kibana chart work together by default in the eck-stack chart.
    elasticsearchRef:
      name: elasticsearch

---
eck-kibana:
  spec:
    # Count of Kibana replicas to create.
    #
    count: 1

    # Reference to ECK-managed Elasticsearch resource, ideally from {{ "elasticsearch.fullname" }}
    #
    elasticsearchRef:
      name: elasticsearch
      namespace: elastic-stack
    http:
      service:
        spec:
          # Type of service to deploy for Kibana.
          # This deploys a load balancer in a cloud service provider, where supported.
          #
          type: LoadBalancer
      # tls:
      #   selfSignedCertificate:
      #     subjectAltNames:
      #     - ip: 1.2.3.4
      #     - dns: kibana.example.com

